<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Matter of Time: Revealing the Structure of Time in Vision-Language Models</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #fff;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 0 20px;
        }

        .header {
            text-align: center;
            padding: 60px 0 40px 0;
            border-bottom: 1px solid #eee;
            margin-bottom: 40px;
        }

        .title {
            font-size: 2.5rem;
            font-weight: 600;
            font-family: 'Times New Roman', Times, serif;
            color: #222;
            margin-bottom: 20px;
            line-height: 1.2;
        }

        .authors {
            font-size: 1.1rem;
            margin-bottom: 10px;
        }

        .authors a {
            color: #0066cc;
            text-decoration: none;
        }

        .authors a:hover {
            text-decoration: underline;
        }

        .affiliations {
            font-size: 0.95rem;
            color: #666;
            margin-bottom: 30px;
        }

        .links {
            margin-top: 20px;
        }

        .btn {
            display: inline-block;
            padding: 8px 16px;
            margin: 0 5px;
            background: #0066cc;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-size: 0.9rem;
            transition: background 0.2s;
        }

        .btn:hover {
            background: #0052a3;
        }

        .section {
            margin-bottom: 40px;
        }

        .section h2 {
            font-size: 1.8rem;
            font-weight: 600;
            color: #222;
            margin-bottom: 20px;
            padding-bottom: 8px;
            border-bottom: 2px solid #eee;
        }

        .section h3 {
            font-size: 1.3rem;
            font-weight: 600;
            color: #333;
            margin: 25px 0 15px 0;
        }

        .figure {
            text-align: center;
            margin: 30px 0;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
        }

        .figure-caption {
            font-size: 0.9rem;
            color: #666;
            margin-top: 10px;
            font-style: italic;
        }

        .highlights {
            margin: 30px 0;
        }

        .highlight-item {
            margin-bottom: 25px;
        }

        .highlight-item h4 {
            font-size: 1.1rem;
            font-weight: 600;
            color: #333;
            margin-bottom: 8px;
        }

        .highlight-item p {
            color: #555;
            line-height: 1.6;
        }

        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 20px;
            margin: 25px 0;
            text-align: center;
        }

        .stat {
            padding: 15px;
            border: 1px solid #eee;
            border-radius: 4px;
        }

        .stat-number {
            font-size: 2rem;
            font-weight: 700;
            color: #0066cc;
            display: block;
        }

        .stat-label {
            font-size: 0.9rem;
            color: #666;
            margin-top: 5px;
        }

        .contributions {
            margin: 30px 0;
        }

        .contribution-item {
            margin-bottom: 15px;
            padding-left: 20px;
            position: relative;
        }

        .contribution-item:before {
            content: "â€¢";
            position: absolute;
            left: 0;
            color: #0066cc;
            font-weight: bold;
        }

        .citation-box {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 20px;
            font-family: 'Courier New', monospace;
            font-size: 0.85rem;
            overflow-x: auto;
            margin: 20px 0;
        }

        .categories {
            margin: 20px 0;
            font-size: 0.95rem;
            line-height: 1.8;
        }

        .footer {
            border-top: 1px solid #eee;
            padding: 30px 0;
            text-align: center;
            color: #666;
            font-size: 0.9rem;
            margin-top: 60px;
        }

        @media (max-width: 768px) {
            .title {
                font-size: 2rem;
            }
            
            .stats {
                grid-template-columns: repeat(2, 1fr);
            }
            
            .container {
                padding: 0 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1 class="title">A Matter of Time: Revealing the Structure of Time in Vision-Language Models</h1>
            
            <div class="authors">
                <a href="#">Nidham TekayaÂ¹</a>,
                <a href="#">Manuela WaldnerÂ²</a>,
                <a href="#">Matthias ZeppelzauerÂ¹</a>
            </div>
            
            <div class="affiliations">
                Â¹ St. PÃ¶lten University of Applied Sciences, Austria<br>
                Â² TU Wien, Inst. of Visual Computing & Human-Centered Technology, Austria
            </div>
            
            <div class="links">
                <a href="#" class="btn">ðŸ“„ Paper</a>
                <a href="#" class="btn">ðŸ’¾ Dataset</a>
                <a href="#" class="btn">ðŸ’» Code</a>
            </div>
        </header>

        <main>
            <div class="figure">
                <img src="./images/teaser.png" alt="Research Overview - Time Assessment Pipeline">
                <div class="figure-caption">
                    <strong>Overview:</strong> (a) Time prompts and query images serve as inputs, (b) VLM processes inputs through text and image encoders, (c) Time embeddings form a chronological manifold in 3D space, (d) Images are mapped to timeline positions, (e) Final temporal predictions are output.
                </div>
            </div>

            <section class="section">
                <h2>Highlights</h2>
                
                <div class="highlights">
                    <div class="highlight-item">
                        <h4>Timeline Construction</h4>
                        <p>We discover that temporal information forms a low-dimensional manifold in VLM embedding spaces. Our BÃ©zier curve approach explicitly models chronological progression, enabling efficient temporal inference through geometric timeline representations.</p>
                    </div>
                    
                    <div class="highlight-item">
                        <h4>TIME10k Dataset</h4>
                        <p>A comprehensive benchmark with 10,091 temporally annotated images spanning 309 years (1715-2024) across 6 object categories: Aircraft, Cars, Mobile Phones, Music Instruments, Ships, and Weapons & Ammunition.</p>
                    </div>
                    
                    <div class="highlight-item">
                        <h4>Time Probing Benchmark</h4>
                        <p>Systematic evaluation of 37 state-of-the-art VLMs reveals significant temporal awareness capabilities. EVA-CLIP and OpenCLIP achieve the best performance with 6.2-6.3 year Mean Absolute Error and 0.85-0.86 Time Awareness Index.</p>
                    </div>
                    
                    <div class="highlight-item">
                        <h4>Temporal Manifold Discovery</h4>
                        <p>First discovery that temporal information can be represented as a ~13-dimensional non-linear manifold within high-dimensional VLM embedding spaces, enabling both analysis and practical applications.</p>
                    </div>
                </div>

                <div class="figure">
                    <img src="./images/timeline-construction.png" alt="Timeline Construction with BÃ©zier Curves">
                    <div class="figure-caption">
                        <strong>Timeline Construction:</strong> (a) Time embeddings with control points, (b) BÃ©zier curve fitting process, (c) Final timeline with image embeddings mapped to temporal positions.
                    </div>
                </div>

                <div class="figure">
                    <img src="./images/benchmark-results.png" alt="VLM Performance Benchmark Results">
                    <div class="figure-caption">
                        <strong>Benchmark Results:</strong> Performance evaluation of 37 VLMs showing Mean Absolute Error (left) and Time Awareness Index (right) across different model releases and architectures.
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Key Contributions</h2>
                <div class="contributions">
                    <div class="contribution-item">
                        <strong>TIME10k Dataset:</strong> A temporally annotated dataset with over 10,000 images from 6 classes of objects, enabling systematic evaluation and comparison of VLMs with respect to temporal awareness and time prediction capabilities.
                    </div>
                    <div class="contribution-item">
                        <strong>Comprehensive Evaluation:</strong> A framework for objectively evaluating time-awareness and investigating 37 state-of-the-art VLMs, examining various backbones, architectures, and prompting strategies.
                    </div>
                    <div class="contribution-item">
                        <strong>Timeline Modeling:</strong> A novel approach for deriving explicit "timeline" representations from VLM embedding spaces using UMAP and BÃ©zier curve approximation.
                    </div>
                    <div class="contribution-item">
                        <strong>Temporal Structure Discovery:</strong> First discovery that temporal information forms a low-dimensional, non-linear manifold in VLM embedding spaces with strong chronological structure.
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Dataset Statistics</h2>
                
                <div class="stats">
                    <div class="stat">
                        <span class="stat-number">10,091</span>
                        <div class="stat-label">Total Images</div>
                    </div>
                    <div class="stat">
                        <span class="stat-number">6</span>
                        <div class="stat-label">Object Categories</div>
                    </div>
                    <div class="stat">
                        <span class="stat-number">309</span>
                        <div class="stat-label">Years Covered</div>
                    </div>
                    <div class="stat">
                        <span class="stat-number">37</span>
                        <div class="stat-label">VLMs Evaluated</div>
                    </div>
                </div>

                <div class="categories">
                    <strong>Aircraft:</strong> 69 images (1893-2017) | <strong>Cars:</strong> 4,393 images (1888-2024) | <strong>Mobile Phones:</strong> 4,337 images (1984-2024)<br>
                    <strong>Music Instruments:</strong> 436 images (1715-2009) | <strong>Ships:</strong> 841 images (1744-1999) | <strong>Weapons & Ammo:</strong> 15 images (1939-2003)
                </div>

                <div class="figure">
                    <img src="./images/dataset-samples.png" alt="TIME10k Dataset Samples">
                    <div class="figure-caption">
                        <strong>TIME10k Dataset Samples:</strong> Representative images from all six object categories spanning different time periods, showcasing the temporal diversity and historical range of our benchmark dataset.
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>Citation</h2>
                <div class="citation-box">
@article{tekaya2024matter,
  title={A Matter of Time: Revealing the Structure of Time in Vision-Language Models},
  author={Tekaya, Nidham and Waldner, Manuela and Zeppelzauer, Matthias},
  journal={Conference Proceedings},
  year={2024}
}
                </div>
            </section>
        </main>

        <footer class="footer">
            <p>&copy; 2024 A Matter of Time - Investigating Temporal Awareness in Vision-Language Models</p>
        </footer>
    </div>
</body>
</html>